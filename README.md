# Exploring distinctive features for various projects using unsupverised clustering algorithm
In this project, I applied K-Prototypes clustering and anomaly detection to discover patterns in the dataset keeping in mind the potential benefits the stakeholders can get from the model.

   ğŸ’¡ Instead of using K-Means clustering which is best suited for contuinuous variables, I used K-Prototypes clustering to handle a mix of categorical and continuous variables present in my dataset. 

## ğŸŒ About Kickstarter
[Kickstarter](https://www.kickstarter.com) is a platform where creators share their project visions with the communities that will come together to fund them.

## ğŸ† What did I discover?
By grouping the projects using clustering algorithm, the management could uncover distinct characteristics within each cluster. Below are the unique characteristics of 8 clusters.
#### âš–ï¸ Moderate Goals, Quick Launchers
These projects showed a preference for swift project initiation, and the pledged amount tended to increase as the launch- to-deadline period extended.
#### ğŸ“† High Goals, Recent Projects
Projects with high fundraising goals and recent deadlines. Interestingly, some projects in this cluster managed to attract a high number of backers, even with lofty fundraising goals.
#### ğŸ‘¥ Backer-Friendly Projects
This cluster stood out for its projects' ability to attract a significant number of backers.
#### ğŸ’¡ Modest Achievers
These projects struck a balance between goal and backers, with an average duration between project creation and launch.
#### ğŸ‘ Well-Supported Initiatives
Projects in this cluster enjoyed high backers and pledged amounts. These projects maintained a relatively low goal and were picked by staff, potentially for the spotlight.
#### ğŸš€ Rapid Projects
This cluster embodied a preference for rapid project development and execution.
#### ğŸ¯ Ambitious Newcomers
With a 24% success rate, Cluster 7 features projects with relatively higher fundraising goals compared to the amount pledged.
#### ğŸ•°ï¸ Long-Term High-Stakes
Cluster 8, with a 29% success rate, represents projects with the highest fundraising goals across clusters. Notably, these projects were created a long time back, suggesting a lower success rate over time.
![image](Images/pair_plots_numeric.png)

## ğŸ› ï¸ How did I achieve this? 
Below is the detailed process for model building.
1. ğŸ§¹ Data preprocessing:
   - Removed non-informative columns including ğ‘–ğ‘‘, ğ‘›ğ‘ğ‘šğ‘’, ğ‘›ğ‘ğ‘šğ‘’_ğ‘™ğ‘’ğ‘›, ğ‘ğ‘™ğ‘¢ğ‘Ÿğ‘_ğ‘™ğ‘’ğ‘›, and ğ‘ğ‘™ğ‘’ğ‘‘ğ‘”ğ‘’ğ‘‘.
   - Created a new feature, ğ‘”ğ‘œğ‘ğ‘™_ğ‘¢ğ‘ ğ‘‘, by multiplying ğ‘”ğ‘œğ‘ğ‘™ and ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘_ğ‘¢ğ‘ ğ‘‘_ğ‘Ÿğ‘ğ‘¡ğ‘’.
   - Replaced non-US countries with 'Non-US' and filled missing values in ğ‘ğ‘ğ‘¡ğ‘’ğ‘”ğ‘œğ‘Ÿğ‘¦ with 'No Category'.
   - Dropped irrelevant columns like original date columns and hour-specific columns.
2. ğŸ” Anomaly detection:
   - Before running any clustering algorithm, I ran an Isolation Forest Model for Anomaly Detection to identify and remove anomalies. The model deteted 1,344 anomalies with unusually high ğ‘”ğ‘œğ‘ğ‘™_ğ‘¢ğ‘ ğ‘‘, ğ‘ğ‘ğ‘ğ‘˜ğ‘’ğ‘Ÿğ‘ _ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ and ğ‘¢ğ‘ ğ‘‘_ğ‘ğ‘™ğ‘’ğ‘‘ğ‘”ğ‘’ğ‘‘.
3. ğŸ¤– Clustering model:
   - Applied K-Prototypes clustering to accommodate both the numerical and categorical features.
   - By testing cost function for different values of K for K-Prototypes Clustering, I could observe [K=8 and K=10 are the elbow points](Images/k-prototype-elbow.png) at which the cost drops drastically. I chose K=8 since it was giving me better business interpretations.

## ğŸ‰ Conclusion
In summary, the K-Prototypes clustering algorithm provided valuable insights into diverse project profiles, offering a comprehensive understanding of Kickstarter projects. Overall, successful projects have high number of backers, pledged amounts, and are staff-picked, ultimately securing a place on Kickstarter spotlight page.

## â—ï¸ Challenges faced
When it comes to computation of performance, it is hard to measure â€˜distanceâ€™ between categorical variables. Instead, it is more suitable to assess the "dissimilarity" between categorical variables. To address this, I attempted to use 'kprototypes.matching_dissim' and 'kprototypes.check_distance' to compute dissimilarity for categorical variables and distance for continuous ones. My goal was to obtain the silhouette score, but unfortunately, I encountered errors in the process.

## ğŸ”— Supporting files
- ğŸ‘©â€ğŸ’» [Python script for clustering models](kickstarter-clustering-models.py)
- ğŸ“ [Entire dataset](kickstarter.xlsx) and [Data Dictionary](kickstarter-data-dictionary.xlsx)
- ğŸ“Š [Data exploration and other charts](Images)

